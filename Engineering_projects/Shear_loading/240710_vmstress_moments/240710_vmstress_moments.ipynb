{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f213a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "quantity = \"tdd\"\n",
    "save_file_number = \"700\"\n",
    "output_folder_loc = f\"/Volumes/Extreme SSD/mac_data/shear_data/\\\n",
    "{quantity}_data/{save_file_number}/moments_{quantity}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8eb545",
   "metadata": {},
   "source": [
    "# Test My understanding about moments.\n",
    "- First let us know if the moment formulae I know are same as what are being used in python.\n",
    "- For this we will first generate some random data and calculate the moments in the way I know.\n",
    "- Later I want to test if my understanding of moments is same as the pythons convention\n",
    "\n",
    "## My definition of moments:\n",
    "Let us say we have $X_1, X_2,X_3, ...,X_N$ data.\n",
    "\n",
    "### Mean:\n",
    "$$\\mu = \\frac{1}{N}\\Sigma(X_k)$$\n",
    "\n",
    "### Variance (or) second central moment:\n",
    "$$ var = \\frac{1}{N}\\Sigma(X_i - \\mu)^2$$\n",
    "\n",
    "### Standard Deviation:\n",
    "$$std = \\sqrt{var}$$\n",
    "\n",
    "### Kth Central Moment\n",
    "$$ M_k = \\frac{1}{N}\\Sigma(X_i - \\mu)^k $$\n",
    "\n",
    "### Kth Standard Moment\n",
    "$$ \\tilde{M_k} = \\frac{M_k}{(std)^k} = \\frac{1}{(std)^k}\\frac{1}{N}\\Sigma(X_i - \\mu)^k $$\n",
    "\n",
    "### Skewness or 3rd Standard Moment \n",
    "$$skew = \\frac{1}{(std)^3}\\frac{1}{N}\\Sigma(X_i - \\mu)^3 $$\n",
    "\n",
    "### Kurtosis or 4rd Moment \n",
    "$$skew = \\frac{1}{(std)^4}\\frac{1}{N}\\Sigma(X_i - \\mu)^4 $$\n",
    "\n",
    "Based on the above definitions let me create a function such that upon inputting the data it gives out the mean, variance, skewness and kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a4f893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 4 moments of the data as calculated by me are given by: \n",
      " [0.9959928722749182, 0.33106947837141415, 0.0023398920202809966, 1.8035875127224592]\n",
      "The 4 moments of the data as calculated by Python Libraries are given by: \n",
      " [0.9959928722749182, 0.33106947837141415, 0.0023398920202809957, 1.8035875127224588]\n",
      "error = [0.00000000e+00 0.00000000e+00 8.67361738e-19 4.44089210e-16]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def my_moments(data):\n",
    "    # Calculating the mean from numpy\n",
    "    my_mean = np.mean(data)\n",
    "    # Evaluating X-mu\n",
    "    central_data = data - my_mean\n",
    "    #Evaluating my variance\n",
    "    my_var = np.mean(central_data**2)\n",
    "    #Evaluating standard deviation\n",
    "    my_std = np.sqrt(my_var)\n",
    "    #Evaulating skewness\n",
    "    my_skew = np.mean(central_data**3)/my_std**3\n",
    "    #Evaluating Kurtosis\n",
    "    my_kurt = np.mean(central_data**4)/my_std**4\n",
    "    \n",
    "    return [my_mean, my_var, my_skew, my_kurt]\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "a = np.random.uniform(0,2,10000)\n",
    "\n",
    "\n",
    "\n",
    "library_moments = [np.mean(a),np.var(a),\n",
    "                 stats.skew(a),stats.kurtosis(a,fisher=False)]\n",
    "\n",
    "print(f\"The 4 moments of the data as calculated by me are given by: \\n {my_moments(a)}\")\n",
    "print(f\"The 4 moments of the data as calculated by Python Libraries are given by: \\n {library_moments}\")\n",
    "print(f\"error = {np.array(my_moments(a))-np.array(library_moments)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95e0e5b",
   "metadata": {},
   "source": [
    "Therefore we will use the following from now on:\n",
    "1. mean = np.mean(data)\n",
    "2. var = np.var(data)\n",
    "3. skewness = scipy.skew(data)\n",
    "4. kurtosis = scipy.kurtosis(data,fisher=off)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8840cb36",
   "metadata": {},
   "source": [
    "Earlier we have plotted the histograms now let us evaluate the first 6 moments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58871e10",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "[Errno 60] Operation timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m file_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_index\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m input_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/Jayee/Library/CloudStorage/OneDrive-UW-Madison/PhD(Data)/shear_data/vm_data/vm_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_file_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/vm_stress/vm_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_file_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 31\u001b[0m vmstress\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#calculating the mean\u001b[39;00m\n\u001b[1;32m     33\u001b[0m [m[_],v[_],s[_],k[_],[m5[_],m6[_]]] \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mmean(vmstress),\n\u001b[1;32m     34\u001b[0m                    np\u001b[38;5;241m.\u001b[39mvar(vmstress),\n\u001b[1;32m     35\u001b[0m                    stats\u001b[38;5;241m.\u001b[39mskew(vmstress),\n\u001b[1;32m     36\u001b[0m                    stats\u001b[38;5;241m.\u001b[39mkurtosis(vmstress,fisher\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m     37\u001b[0m                    my_moments(vmstress)]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/lib/npyio.py:434\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    432\u001b[0m _ZIP_SUFFIX \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPK\u001b[39m\u001b[38;5;130;01m\\x05\u001b[39;00m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# empty zip files start with this\u001b[39;00m\n\u001b[1;32m    433\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX)\n\u001b[0;32m--> 434\u001b[0m magic \u001b[38;5;241m=\u001b[39m \u001b[43mfid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m magic:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data left in file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 60] Operation timed out"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "def my_moments(data):\n",
    "    # Calculating the mean from numpy\n",
    "    my_mean = np.mean(data)\n",
    "    # Evaluating X-mu\n",
    "    central_data = data - my_mean\n",
    "    #Evaluating my variance\n",
    "    my_var = np.mean(central_data**2)\n",
    "    #Evaluating standard deviation\n",
    "    my_std = np.sqrt(my_var)\n",
    "    #Evaulating m5\n",
    "    my_m5 = np.mean(central_data**5)/my_std**5\n",
    "    #Evaluating m6\n",
    "    my_m6 = np.mean(central_data**6)/my_std**6\n",
    "    \n",
    "    return [my_m5,my_m6]\n",
    "\n",
    "# initializing the moments\n",
    "num_of_files = 11\n",
    "[m,v,s,k,m5,m6] = [np.zeros(num_of_files) for __ in range(6)]\n",
    "\n",
    "num_of_files = 11\n",
    "file_index_list = list(range(num_of_files))\n",
    "for _,file_index in enumerate(file_index_list):\n",
    "    file_index = file_index+1\n",
    "    # reading the input file\n",
    "    file_number = f\"{file_index}\"\n",
    "    #file_number = f\"{file_index:03}\"\n",
    "    input_folder = f\"/Users/Jayee/Library/CloudStorage/OneDrive-UW-Madison/PhD(Data)/shear_data/vm_data/vm_{save_file_number}/vm_stress/vm_{save_file_number}_{file_number}.npy\"\n",
    "    vmstress= np.load(input_folder)\n",
    "    #calculating the mean\n",
    "    [m[_],v[_],s[_],k[_],[m5[_],m6[_]]] = [np.mean(vmstress),\n",
    "                       np.var(vmstress),\n",
    "                       stats.skew(vmstress),\n",
    "                       stats.kurtosis(vmstress,fisher=False),\n",
    "                       my_moments(vmstress)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85f7659",
   "metadata": {},
   "source": [
    "## Saving this data as a numpy file\n",
    "- The npy file will have moments organized as columns,i.e., each column represents a different moment.\n",
    "- Let the first column represnt the time axis in micro seconds.\n",
    "- **Time|Mean|Var|Skewness|Kurt|m5|m6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87e222e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.71910000e+00,  1.49252461e+01,  5.43798555e+00,\n",
       "         5.73196526e-02,  2.71731301e+00,  1.17825989e+00,\n",
       "         1.26319760e+01],\n",
       "       [ 2.79360000e+00,  5.09929468e+01,  6.35219056e+01,\n",
       "         5.73297699e-02,  2.71729300e+00,  1.17851521e+00,\n",
       "         1.26317579e+01],\n",
       "       [ 3.65320000e+00,  9.23017766e+01,  2.08293750e+02,\n",
       "         5.73403141e-02,  2.71726663e+00,  1.17878676e+00,\n",
       "         1.26314296e+01],\n",
       "       [ 5.15740000e+00,  2.53409029e+02,  1.52377188e+03,\n",
       "         5.46830727e-02,  2.65892041e+00,  9.47080067e-01,\n",
       "         1.15722980e+01],\n",
       "       [ 6.01700000e+00,  2.82415699e+02,  1.81919504e+03,\n",
       "         1.18147101e-01,  2.56209097e+00,  1.10030021e+00,\n",
       "         1.04431783e+01],\n",
       "       [ 7.52120000e+00,  3.82640906e+02,  3.98023609e+03,\n",
       "         2.22048458e-01,  2.03035389e+00,  1.29342403e+00,\n",
       "         5.85384566e+00],\n",
       "       [ 9.88500000e+00,  5.27208245e+02,  8.36226069e+03,\n",
       "        -1.49564711e-01,  1.84837876e+00, -3.44282932e-01,\n",
       "         4.40358485e+00],\n",
       "       [ 1.22488000e+01,  6.56294659e+02,  1.37700491e+04,\n",
       "        -1.80846336e-01,  1.98389363e+00, -4.00569823e-01,\n",
       "         5.22845843e+00],\n",
       "       [ 1.46126000e+01,  7.21149803e+02,  1.77565611e+04,\n",
       "        -1.56512614e-01,  2.06541264e+00, -2.97838639e-01,\n",
       "         5.80024465e+00],\n",
       "       [ 1.80509000e+01,  7.86623944e+02,  2.19997144e+04,\n",
       "        -1.55480985e-01,  2.09665187e+00, -3.64620170e-01,\n",
       "         6.01064834e+00],\n",
       "       [ 1.97700000e+01,  8.35596429e+02,  2.48018874e+04,\n",
       "        -1.71286503e-01,  2.07965851e+00, -4.75998631e-01,\n",
       "         5.89752290e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the time data points from Noah\n",
    "time = np.array([1.7191,\n",
    "                2.7936,\n",
    "                3.6532,\n",
    "                5.1574,\n",
    "                6.0170,\n",
    "                7.5212,\n",
    "                9.8850,\n",
    "                12.2488,\n",
    "                14.6126,\n",
    "                18.0509,\n",
    "                19.7700])\n",
    "# stacking all the moments.\n",
    "time_moments = np.transpose(np.vstack([time, m,v,s,k,m5,m6]))\n",
    "time_moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5e1c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the file\n",
    "file_name = f\"t_mvskm5m6_{save_file_number}.npy\"\n",
    "file_location = os.path.join(output_folder,file_name)\n",
    "np.save(file_location, time_moments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0bc55e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yh/jc0pysz13d356254dbrfhtth0000gn/T/ipykernel_71830/1635609844.py:24: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  my_m5 = np.mean(central_data**5)/my_std**5\n",
      "/var/folders/yh/jc0pysz13d356254dbrfhtth0000gn/T/ipykernel_71830/1635609844.py:26: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  my_m6 = np.mean(central_data**6)/my_std**6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1 700\n",
      "e1 800\n",
      "e1 801\n",
      "e1 802\n",
      "e2 700\n",
      "e2 800\n",
      "e2 801\n",
      "e2 802\n",
      "e3 700\n",
      "e3 800\n",
      "e3 801\n",
      "e3 802\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "data_number_list = [700,800,801,802]\n",
    "quantity_list = [\"e1\",\"e2\",\"e3\"]\n",
    "for quantity in quantity_list:\n",
    "    for save_file_number in data_number_list:\n",
    "        output_folder_loc = f\"/Volumes/Extreme SSD/mac_data/shear_data/rel_rotat_data/\\\n",
    "{quantity}/{save_file_number}/moments_{quantity}\"\n",
    "        \n",
    "        def my_moments(data):\n",
    "            # Calculating the mean from numpy\n",
    "            my_mean = np.mean(data)\n",
    "            # Evaluating X-mu\n",
    "            central_data = data - my_mean\n",
    "            #Evaluating my variance\n",
    "            my_var = np.mean(central_data**2)\n",
    "            #Evaluating standard deviation\n",
    "            my_std = np.sqrt(my_var)\n",
    "            #Evaulating m5\n",
    "            my_m5 = np.mean(central_data**5)/my_std**5\n",
    "            #Evaluating m6\n",
    "            my_m6 = np.mean(central_data**6)/my_std**6\n",
    "\n",
    "            return [my_m5,my_m6]\n",
    "\n",
    "        # initializing the moments\n",
    "        num_of_files = 11\n",
    "        [m,v,s,k,m5,m6] = [np.zeros(num_of_files) for __ in range(6)]\n",
    "\n",
    "        num_of_files = 11\n",
    "        file_index_list = list(range(num_of_files))\n",
    "        for _,file_index in enumerate(file_index_list):\n",
    "            file_index = file_index+1\n",
    "            # reading the input file\n",
    "            file_number = f\"{file_index}\"\n",
    "            #file_number = f\"{file_index:03}\"\n",
    "#           input_folder = f\"/Users/Jayee/Library/CloudStorage/OneDrive-UW-Madison/PhD(Data)/\\\n",
    "# shear_data/vm_data/vm_{save_file_number}/vm_stress/vm_{save_file_number}_{file_number}.npy\"\n",
    "            input_folder = f\"/Volumes/Extreme SSD/mac_data/shear_data/rel_rotat_data/\\\n",
    "{quantity}/{save_file_number}/{quantity}/Step-{file_number}.npy\"\n",
    "            vmstress= np.load(input_folder)\n",
    "            #calculating the mean\n",
    "            [m[_],v[_],s[_],k[_],[m5[_],m6[_]]] = [np.mean(vmstress),\n",
    "                               np.var(vmstress),\n",
    "                               stats.skew(vmstress),\n",
    "                               stats.kurtosis(vmstress,fisher=False),\n",
    "                               my_moments(vmstress)]\n",
    "            # Defining the time data points from Noah\n",
    "        time = np.array([1.7191,\n",
    "                        2.7936,\n",
    "                        3.6532,\n",
    "                        5.1574,\n",
    "                        6.0170,\n",
    "                        7.5212,\n",
    "                        9.8850,\n",
    "                        12.2488,\n",
    "                        14.6126,\n",
    "                        18.0509,\n",
    "                        19.7700])\n",
    "        # stacking all the moments.\n",
    "        time_moments = np.transpose(np.vstack([time, m,v,s,k,m5,m6]))\n",
    "        time_moments\n",
    "\n",
    "        # Saving the file\n",
    "        file_name = f\"t_mvskm5m6_{save_file_number}.npy\"\n",
    "        file_location = os.path.join(output_folder_loc,file_name)\n",
    "        np.save(file_location, time_moments)\n",
    "        print(quantity,save_file_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e20e378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
