{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51c35032-56c6-4857-8f21-af45e4b98fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1000)\n",
    "np.random.seed(1000)\n",
    "\n",
    "parser = argparse.ArgumentParser('ODE demo')\n",
    "parser.add_argument('--method', type=str, choices=['dopri5', 'adams'], default='dopri5')\n",
    "parser.add_argument('--data_size', type=int, default=1000)\n",
    "parser.add_argument('--batch_time', type=int, default=15)\n",
    "parser.add_argument('--batch_size', type=int, default=100)\n",
    "parser.add_argument('--niters', type=int, default=2000)\n",
    "parser.add_argument('--test_freq', type=int, default=20)\n",
    "parser.add_argument('--viz', action='store_true')\n",
    "parser.add_argument('--gpu', type=int, default=0)\n",
    "parser.add_argument('--adjoint', action='store_true')\n",
    "\n",
    "# Parse arguments when running in Jupyter notebook\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "if args.adjoint:\n",
    "    from torchdiffeq import odeint_adjoint as odeint\n",
    "else:\n",
    "    from torchdiffeq import odeint\n",
    "\n",
    "device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1d6ede8-82e9-4c7b-a9c0-e6c4bc8f3faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct a neural network to approximate the dynamics of an ODE\n",
    "class ODEFuncMean(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ODEFuncMean, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(5, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 1)\n",
    "        ).to(torch.float64)\n",
    "\n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "                nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        return self.net(y)\n",
    "    \n",
    "funcMean = ODEFuncMean().to(device)\n",
    "\n",
    "## Construct a neural network to approximate the dynamics of an ODE\n",
    "class ODEFuncVariance(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ODEFuncVariance, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(5, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "                nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        return self.net(y)\n",
    "    \n",
    "funcVariance = ODEFuncVariance().to(device)\n",
    "\n",
    "## Construct a neural network to approximate the dynamics of an ODE\n",
    "class ODEFuncSkewness(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ODEFuncSkewness, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(5, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "                nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        return self.net(y)\n",
    "    \n",
    "funcSkewness = ODEFuncSkewness().to(device)\n",
    "\n",
    "## Construct a neural network to approximate the dynamics of an ODE\n",
    "class ODEFuncKurtosis(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ODEFuncKurtosis, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(5, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "                nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        return self.net(y)\n",
    "    \n",
    "funcKurtosis = ODEFuncKurtosis().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df25ad6b-c034-4843-b770-e66ee25fd59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def combined_system_mean(tVar, y):   \n",
    "    dt_dt = 1.0\n",
    "    dt_dt = torch.tensor([dt_dt])\n",
    "    \n",
    "    dm_dt = funcMean(tVar, y)\n",
    "    \n",
    "    dv_dt = dv_dt_fun(tVar.item()).item()\n",
    "    dv_dt = torch.tensor([dv_dt]).to(dtype=torch.double)\n",
    "    \n",
    "    ds_dt = ds_dt_fun(tVar.item()).item()\n",
    "    ds_dt = torch.tensor([ds_dt]).to(dtype=torch.double)\n",
    "    \n",
    "    dk_dt = dk_dt_fun(tVar.item()).item()\n",
    "    dk_dt = torch.tensor([dk_dt]).to(dtype=torch.double)\n",
    "    \n",
    "    return torch.cat([dm_dt, dv_dt, ds_dt, dk_dt, dt_dt], dim=0)\n",
    "\n",
    "def combined_system_var(tVar, y):   \n",
    "    dt_dt = 1.0\n",
    "    dt_dt = torch.tensor([dt_dt])\n",
    "\n",
    "    dm_dt = dm_dt_fun(tVar.item()).item()\n",
    "    dm_dt = torch.tensor([dm_dt]).to(dtype=torch.double)\n",
    "    \n",
    "    dv_dt = funcVariance(tVar, y)\n",
    "        \n",
    "    ds_dt = ds_dt_fun(tVar.item()).item()\n",
    "    ds_dt = torch.tensor([ds_dt]).to(dtype=torch.double)\n",
    "    \n",
    "    dk_dt = dk_dt_fun(tVar.item()).item()\n",
    "    dk_dt = torch.tensor([dk_dt]).to(dtype=torch.double)\n",
    "    \n",
    "    return torch.cat([dm_dt, dv_dt, ds_dt, dk_dt, dt_dt], dim=0)\n",
    "\n",
    "def combined_system_skw(tVar, y):   \n",
    "    dt_dt = 1.0\n",
    "    dt_dt = torch.tensor([dt_dt])\n",
    "\n",
    "    dm_dt = dm_dt_fun(tVar.item()).item()\n",
    "    dm_dt = torch.tensor([dm_dt]).to(dtype=torch.double)\n",
    "    \n",
    "    dv_dt = dv_dt_fun(tVar.item()).item()\n",
    "    dv_dt = torch.tensor([dv_dt]).to(dtype=torch.double)\n",
    "        \n",
    "    ds_dt = funcSkewness(tVar,y)\n",
    "    \n",
    "    dk_dt = dk_dt_fun(tVar.item()).item()\n",
    "    dk_dt = torch.tensor([dk_dt]).to(dtype=torch.double)\n",
    "    \n",
    "    return torch.cat([dm_dt, dv_dt, ds_dt, dk_dt, dt_dt], dim=0)\n",
    "\n",
    "def combined_system_kurt(tVar, y):   \n",
    "    dt_dt = 1.0\n",
    "    dt_dt = torch.tensor([dt_dt])\n",
    "\n",
    "    dm_dt = dm_dt_fun(tVar.item()).item()\n",
    "    dm_dt = torch.tensor([dm_dt]).to(dtype=torch.double)\n",
    "    \n",
    "    dv_dt = dv_dt_fun(tVar.item()).item()\n",
    "    dv_dt = torch.tensor([dv_dt]).to(dtype=torch.double)\n",
    "        \n",
    "    ds_dt = ds_dt_fun(tVar.item()).item()\n",
    "    ds_dt = torch.tensor([ds_dt]).to(dtype=torch.double)\n",
    "    \n",
    "    dk_dt = funcKurtosis(tVar,y)\n",
    "    \n",
    "    return torch.cat([dm_dt, dv_dt, ds_dt, dk_dt, dt_dt], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d55e726-7176-4b54-b41b-9decbcc7d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "\n",
    "matrix= scipy.io.loadmat(\"/home/ponnana/PhD/Yinling_copy/data_new.mat\")\n",
    "\n",
    "m = matrix[\"data_new\"][:,0]\n",
    "v =  matrix[\"data_new\"][:,1]\n",
    "s = matrix[\"data_new\"][:,2]\n",
    "k = matrix[\"data_new\"][:,3]\n",
    "\n",
    "tExp = [0.01058, 0.03158, 0.05258, 0.07358, 0.09458, 0.1156, 0.1366, 0.1576, 0.1786, 0.1996, 0.2206,\n",
    "          0.2300, 0.2756, 0.3316, 0.3876, 0.4436, 0.4496, 0.5556, 0.6116, 0.6676, 0.7206, 0.7796, 0.8356,\n",
    "          0.8916, 0.9476, 1.004, 1.060, 1.105, 1.124, 1.153, 1.182, 1.211, 1.240, 1.269, 1.298, 1.327,\n",
    "          1.356, 1.385, 1.414, 1.443, 1.472, 1.501, 1.530, 1.559, 1.588, 1.617, 1.646, 1.670]\n",
    "\n",
    "tExp = np.array(tExp)\n",
    "\n",
    "\n",
    "t1,t2 = 0.24,1.1\n",
    "xExp = np.concatenate((matrix[\"data_new\"], tExp.reshape(-1,1)), axis=1)\n",
    "# xExp = xExp.astype(double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad43b12e-60eb-40ea-bba1-1384bd41aa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxValues = np.max(xExp,axis=0)\n",
    "maxValues[-1]=1\n",
    "xExpNormal = xExp/maxValues\n",
    "truncIndex = np.where(xExpNormal[:,1]>=0.0999)\n",
    "xExpTruncNormal = xExpNormal[truncIndex,:]\n",
    "xExpTruncNormal = np.squeeze(xExpTruncNormal)\n",
    "\n",
    "tExpTrunc = xExpTruncNormal[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d4eaced-fbf3-44e3-9401-8561f9cdbd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "tTrain = np.linspace(np.min(tExpTrunc), np.max(tExpTrunc), args.data_size)\n",
    "quad_interp = interp1d(tExpTrunc, xExpTruncNormal, kind='quadratic', axis=0)\n",
    "xTrain = quad_interp(tTrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3695c03-38d7-43bd-a271-4377468e9354",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmeanBydtTemp = xTrain[1:,0]-xTrain[0:-1,0]\n",
    "dvarBydtTemp = xTrain[1:,1]-xTrain[0:-1,1]\n",
    "dskwBydtTemp = xTrain[1:,2]-xTrain[0:-1,2]\n",
    "dkurtBydtTemp = xTrain[1:,3]-xTrain[0:-1,3]\n",
    "timeStep= tTrain[1]-tTrain[0]\n",
    "\n",
    "dmeanBydtTemp = dmeanBydtTemp/timeStep\n",
    "dvarBydtTemp = dvarBydtTemp/timeStep\n",
    "dskwBydtTemp = dskwBydtTemp/timeStep\n",
    "dkurtBydtTemp = dkurtBydtTemp/timeStep\n",
    "\n",
    "dmeanBydt = np.append(dmeanBydtTemp,dmeanBydtTemp[-1])\n",
    "dvarBydt = np.append(dvarBydtTemp,dvarBydtTemp[-1])\n",
    "dskwBydt = np.append(dskwBydtTemp,dskwBydtTemp[-1])\n",
    "dkurtBydt = np.append(dkurtBydtTemp,dkurtBydtTemp[-1])\n",
    "\n",
    "dm_dt_fun = interp1d(tTrain, dmeanBydt, axis=0, fill_value='extrapolate')\n",
    "dv_dt_fun = interp1d(tTrain, dvarBydt, axis=0, fill_value='extrapolate')\n",
    "ds_dt_fun = interp1d(tTrain, dskwBydt, axis=0, fill_value='extrapolate')\n",
    "dk_dt_fun = interp1d(tTrain, dkurtBydt, axis=0, fill_value='extrapolate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85cb2055-9116-4ee4-8ddd-0d6b3e61d9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2J"
     ]
    }
   ],
   "source": [
    "clear true_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb2a3a4f-5d78-41fe-b65a-05d99e07358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up the true system\n",
    "true_y0 = torch.from_numpy(xTrain[0,:]).to(device).to(dtype=torch.double)\n",
    "t = torch.from_numpy(tTrain).to(dtype=torch.double)\n",
    "true_y = torch.from_numpy(xTrain).unsqueeze(1).to(dtype=torch.double)\n",
    "\n",
    "## Get mini-batch data from the training dataset \n",
    "def get_batch():\n",
    "    s = torch.from_numpy(np.random.choice(np.arange(args.data_size - args.batch_time, dtype=np.int64), args.batch_size, replace=False))\n",
    "    batch_y0 = true_y[s]  # (M, D)\n",
    "    batch_t = torch.stack([t[i:i+args.batch_time] for i in s]) # (T)\n",
    "    batch_y = torch.stack([true_y[s + i] for i in range(args.batch_time)], dim=1)  # (T, M, D)\n",
    "    batch_y=batch_y.permute(2,0,1,3)\n",
    "    return batch_y0.to(device), batch_t.to(device), batch_y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8aa261a-4a50-4525-8e44-301ac5aa88e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mean.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m funcMeanLoaded \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m funcSkwLoaded \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskewness.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m funcVarLoaded \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariance.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mean.pth'"
     ]
    }
   ],
   "source": [
    "funcMeanLoaded = torch.load('mean.pth')\n",
    "funcSkwLoaded = torch.load('skewness.pth')\n",
    "funcVarLoaded = torch.load('variance.pth')\n",
    "funcKurtLoaded = torch.load('kurtosis.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39ef479c-06c8-4ff2-b0b3-7f3ac0962ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ponnana'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
